#!/usr/bin/env python3
from argparse import ArgumentParser, FileType

from Mikado.parsers import parser_factory
from Mikado.transcripts import Transcript, Gene
from networkx import Graph, connected_components


def minimal_gxf_parser(parser):
    genes = dict()
    tid2gid = dict()
    for row in parser:
        if row.header is True:
            continue
        elif row.is_gene is True:
            genes[row.id] = Gene(row)
        elif row.is_transcript is True:
            assert len(row.parent) == 1
            parent = row.parent[0]
            tid2gid[row.id] = parent
            genes[parent].add(Transcript(row))
        elif row.is_exon is True:
            if row.gene is None:
                gene = tid2gid[row.parent[0]]
            else:
                gene = row.gene
            genes[gene].add_exon(row)

    for gene in genes:
        genes[gene].finalize()
    return genes, tid2gid


def main():
    parser = ArgumentParser()
    parser.add_argument('-b', '--blast_hits', type=FileType('r'), help='Hits from self blast check')
    parser.add_argument('-c', '--classification', type=FileType('r'), help='Transcript full length classification')
    parser.add_argument('-t', '--transcripts', type=FileType('r'), help='Transcripts checking for self hits')
    parser.add_argument('-n', '--top_n', type=int, default=2000, help='Only output the top N transcripts')
    args = parser.parse_args()

    print(f"Parsing input transcripts {args.transcripts.name}")

    # Parse transcripts and hits
    genes, tid2gid = minimal_gxf_parser(parser_factory(args.transcripts.name))

    print(f"Found {len(tid2gid)} transcripts")
    print(f"Calculating 80cov80id redundant groups")
    # If hit matches something else with 80cov 80id add edge to graph
    edges = []
    for hit_line in args.blast_hits:
        qseqid, sseqid, qlen, slen, pident, length, mismatch, \
        gapopen, qstart, qend, sstart, send, evalue, bitscore, ppos, btop = hit_line.strip().split('\t')
        if qseqid == sseqid:
            continue
        scov = 100 * (int(send) - int(sstart) + 1) / int(slen)
        qcov = 100 * (int(qend) - int(qstart) + 1) / int(qlen)
        cov = min(scov, qcov)
        if float(pident) > 80 and cov > 80:
            edges.append(sorted((qseqid, sseqid)))

    # Parse the classification to obtain the scores
    next(args.classification)
    txct_scores = {}
    for i, l in enumerate(args.classification):
        record = l.strip().split('\t')
        txct_scores[record[4]] = (float(record[8]), i, record[6])

    # From connected components pick the best element to print and 'filter' the rest
    graph = Graph()
    graph.add_edges_from(edges)
    discard = set()
    ccomponents = 0
    for ccomponents, component in enumerate(connected_components(graph)):
        keep = max(component, key=lambda txtc_id: txct_scores.get(txtc_id, (-1.0, -1, '\0')))  # \0 as is smallest char
        component.remove(keep)
        discard.update(component)
    print(f"Found {ccomponents} groups of similar transcripts")

    print(f"Discarding {len(discard)} transcripts as redundant by sequence content")
    print("Generating output files")
    # Output the top N models models not in the 'discard' pile from (gold+silver), (gold+silver+bronze)
    for piles in [
        (open('with_utr.gff', 'w'), {'Gold', 'Silver'}),
        (open('without_utr.gff', 'w'), {'Gold', 'Silver', 'Bronze'})
    ]:
        num_output = 0
        for tid, scores in txct_scores.items():
            if tid in discard:
                continue
            if scores[2] not in piles[1]:
                continue
            if num_output >= args.top_n:
                break
            gene = genes[tid2gid[tid]]
            print(gene.__str__().split('\n')[0], file=piles[0])
            print(gene[tid].format('gff'), file=piles[0])
            print('###', file=piles[0])
            num_output += 1
        print(f"{num_output} transcripts generated in {piles[0].name}")


if __name__ == "__main__":
    main()
