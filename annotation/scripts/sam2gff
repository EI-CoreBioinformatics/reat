#!/usr/bin/env python3

import os
import sys
import errno
import re
import subprocess
import pdb
from math import floor
from collections import namedtuple, Counter
from six.moves import urllib
from argparse import ArgumentParser

from Bio import SeqIO
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
from Bio.SeqFeature import SeqFeature, FeatureLocation

Interval = namedtuple('Interval', ['start', 'end'])


class _IdHandler:
    """Generate IDs for GFF3 Parent/Child relationships where they don't exist.
    """

    def __init__(self):
        self._prefix = "biopygen"
        self._counter = 1
        self._seen_ids = []

    def _generate_id(self, quals):
        """Generate a unique ID not present in our existing IDs.
        """
        gen_id = self._get_standard_id(quals)
        if gen_id is None:
            while 1:
                gen_id = "%s%s" % (self._prefix, self._counter)
                if gen_id not in self._seen_ids:
                    break
                self._counter += 1
        return gen_id

    def _get_standard_id(self, quals):
        """Retrieve standardized IDs from other sources like NCBI GenBank.
        This tries to find IDs from known key/values when stored differently
        than GFF3 specifications.
        """
        possible_keys = ["transcript_id", "protein_id"]
        for test_key in possible_keys:
            if test_key in quals:
                cur_id = quals[test_key]
                if isinstance(cur_id, tuple) or isinstance(cur_id, list):
                    return cur_id[0]
                else:
                    return cur_id
        return None

    def update_quals(self, quals, has_children):
        """Update a set of qualifiers, adding an ID if necessary.
        """
        cur_id = quals.get("ID", None)
        # if we have an ID, record it
        if cur_id:
            if not isinstance(cur_id, list) and not isinstance(cur_id, tuple):
                cur_id = [cur_id]
            for add_id in cur_id:
                self._seen_ids.append(add_id)
        # if we need one and don't have it, create a new one
        elif has_children:
            new_id = self._generate_id(quals)
            self._seen_ids.append(new_id)
            quals["ID"] = [new_id]
        return quals


class GFF3Writer:
    """Write GFF3 files starting with standard Biopython objects.
    """

    def __init__(self, out_handle):
        self.id_handler = _IdHandler()
        self._out_handle = out_handle
        self._write_header(out_handle)
        pass

    def write(self, rec):
        """Write the provided records to the given handle in GFF3 format.
        """
        self._write_annotations(rec.annotations, rec.id, len(rec.seq), self._out_handle)
        for sf in rec.features:
            sf = self._clean_feature(sf)
            self.id_handler = self._write_feature(sf, rec.id, self._out_handle,
                                                  self.id_handler)
        self._out_handle.write("###\n")

    def _clean_feature(self, feature):
        quals = {}
        for key, val in feature.qualifiers.items():
            if not isinstance(val, (list, tuple)):
                val = [val]
            val = [str(x) for x in val]
            quals[key] = val
        feature.qualifiers = quals
        # Support for Biopython 1.68 and above, which removed sub_features
        if not hasattr(feature, "sub_features"):
            feature.sub_features = []
        clean_sub = [self._clean_feature(f) for f in feature.sub_features]
        feature.sub_features = clean_sub
        return feature

    def _get_phase(self, feature):
        if "phase" in feature.qualifiers:
            phase = feature.qualifiers["phase"][0]
        elif feature.type == "CDS":
            phase = int(feature.qualifiers.get("codon_start", [1])[0]) - 1
        else:
            phase = "."
        return str(phase)

    def _write_feature(self, feature, rec_id, out_handle, id_handler,
                       parent_id=None):
        """Write a feature with location information.
        """
        if feature.strand == 1:
            strand = '+'
        elif feature.strand == -1:
            strand = '-'
        else:
            strand = '.'
        # remove any standard features from the qualifiers
        quals = feature.qualifiers.copy()
        for std_qual in ["source", "score", "phase"]:
            if std_qual in quals and len(quals[std_qual]) == 1:
                del quals[std_qual]
        # add a link to a parent identifier if it exists
        if parent_id:
            if not "Parent" in quals:
                quals["Parent"] = []
            quals["Parent"].append(parent_id)
        quals = id_handler.update_quals(quals, len(feature.sub_features) > 0)
        if feature.type:
            ftype = feature.type
        else:
            ftype = "sequence_feature"
        parts = [str(rec_id),
                 feature.qualifiers.get("source", ["feature"])[0],
                 ftype,
                 str(feature.location.nofuzzy_start + 1),  # 1-based indexing
                 str(feature.location.nofuzzy_end),
                 feature.qualifiers.get("score", ["."])[0],
                 strand,
                 self._get_phase(feature),
                 self._format_keyvals(quals)]
        out_handle.write("\t".join(parts) + "\n")

        for sub_feature in feature.sub_features:
            id_handler = self._write_feature(sub_feature, rec_id, out_handle,
                                             id_handler, quals["ID"][0])

        return id_handler

    def _format_keyvals(self, keyvals):
        format_kvs = []
        for key in sorted(keyvals.keys()):
            values = keyvals[key]
            key = key.strip()
            format_vals = []
            if not isinstance(values, list) or isinstance(values, tuple):
                values = [values]
            for val in values:
                val = urllib.parse.quote(str(val).strip(), safe=":/ ")
                if ((key and val) and val not in format_vals):
                    format_vals.append(val)
            format_kvs.append("%s=%s" % (key, ",".join(format_vals)))
        return ";".join(format_kvs)

    def _write_annotations(self, anns, rec_id, size, out_handle):
        """Add annotations which refer to an entire sequence.
        """
        format_anns = self._format_keyvals(anns)
        if format_anns:
            parts = [rec_id, "annotation", "remark", "1", str(size if size > 1 else 1),
                     ".", ".", ".", format_anns]
            out_handle.write("\t".join(parts) + "\n")

    def _write_header(self, out_handle):
        """Write out standard header directives.
        """
        out_handle.write("##gff-version 3\n")
        out_handle.write("# Generated by sam2gff (2020-02-04) using call: " + " ".join(sys.argv) + "\n")


class SAMReader:
    SAMheaders = ['@HD', '@SQ', '@RG', '@PG', '@CO']

    def __init__(self, filehandle, has_header):
        self.f = filehandle
        self.header = ''
        if has_header:
            while True:
                cur = self.f.tell()
                line = self.f.readline()
                if line[:3] not in SAMReader.SAMheaders:
                    break
                self.header += line
            self.f.seek(cur)

    def __iter__(self):
        return self

    def __next__(self):
        line = self.f.readline().strip()
        if len(line) == 0:
            raise StopIteration
        return SAMRecord(line)


class SAMRecord:
    SAMflag = namedtuple('SAMflag', ['is_paired', 'strand', 'PE_read_num'])

    def __init__(self, record_line=None):
        """
        Designed to handle BowTie SAM output for unaligned reads (PE read not yet supported)
        Can handle map to transfrag (no splicing) and genome (splicing)
        """
        self.qID = None
        self.sID = None
        self.sStart = None
        self.sEnd = None
        self.segments = None
        self.num_nonmatches = None
        self.num_ins = None
        self.num_del = None
        self.num_mat_or_sub = None

        self.qCoverage = None
        self.sCoverage = None

        self.sLen = None
        self.qLen = None
        # qStart, qEnd might get changed in parse_cigar
        self.qStart = 0
        self.qEnd = None  # length of SEQ

        self.cigar = None
        self.flag = None

        self.identity = None
        self.record_line = record_line
        if record_line is not None:
            self.process(record_line)

    def __str__(self):
        msg = \
            """
        qID: {q}
        sID: {s}
        cigar: {c}
        sStart-sEnd: {ss}-{se}
        qStart-qEnd: {qs}-{qe}
        segments: {seg}
        flag: {f}
        
        coverage (of query): {qcov}
        coverage (of subject): {scov}
        alignment identity: {iden}
        """.format(q=self.qID, s=self.sID, seg=self.segments, c=self.cigar, f=self.flag,
                   ss=self.sStart, se=self.sEnd, qs=self.qStart, qe=self.qEnd, iden=self.identity,
                   qcov=self.qCoverage, scov=self.sCoverage)
        return msg

    def __eq__(self, other):
        return self.qID == other.qID and self.sID == other.sID and \
               self.sStart == other.sStart and self.sEnd == other.sEnd and \
               self.segments == other.segments and self.qCoverage == other.qCoverage and \
               self.sCoverage == other.sCoverage and self.qLen == other.qLen and \
               self.sLen == other.sLen and self.qStart == other.qStart and \
               self.cigar == other.cigar and self.flag == other.flag and self.identity == other.identity

    def process(self, record_line):
        """
        If SAM is from pbalign.py output, then have flags:
            XS: 1-based qStart, XE: 1-based qEnd, XQ: query length, NM: number of non-matches
        ignore_XQ should be False for BLASR/pbalign.py's SAM, True for GMAP's SAM
        
        0. qID
        1. flag
        2. sID
        3. 1-based offset sStart
        4. mapping quality (ignore)
        5. cigar
        6. name of ref of mate alignment (ignore)
        7. 1-based offset sStart of mate (ignore)
        8. inferred fragment length (ignore)
        9. sequence (ignore)
        10. read qual (ignore)
        11. optional fields
        """
        raw = record_line.split('\t')
        self.qID = raw[0]
        self.sID = raw[2]
        if self.sID == '*':  # means no match! STOP here
            return
        self.sStart = int(raw[3]) - 1
        self.cigar = raw[5]
        self.segments = self.parse_cigar(self.cigar, self.sStart)
        self.sEnd = self.segments[-1].end
        self.flag = SAMRecord.parse_sam_flag(int(raw[1]))

        # process optional fields
        # XM: number of mismatches
        # NM: edit distance (sub/ins/del)
        for x in raw[11:]:
            if x.startswith('NM:i:'):
                self.num_nonmatches = int(x[5:])
            if x.startswith('XS:A:'):
                self.flag.strand = x[5:]

        if self.flag.strand == '-' and self.qLen is not None:
            self.qStart, self.qEnd = self.qLen - self.qEnd, self.qLen - self.qStart

        if self.num_nonmatches is not None:
            self.identity = 1. - (self.num_nonmatches * 1. / (self.num_del + self.num_ins + self.num_mat_or_sub))

    def parse_cigar(self, cigar, start):
        """
        M - match
        I - insertion w.r.t. to ref
        D - deletion w.r.t. to ref
        N - skipped (which means splice junction)
        S - soft clipped
        H - hard clipped (not shown in SEQ)
        = - read match
        X - read mismatch
        ex: 50M43N3D
        NOTE: sets qStart & qEnd, which are often incorrect because of different ways to write CIGAR strings
        Returns: genomic segment locations (using <start> as offset)
        """
        segments = []
        cur_start = start
        cur_end = start
        first_thing = True
        q_aln_len = 0
        self.num_del = 0
        self.num_ins = 0
        self.num_mat_or_sub = 0
        for (num, type) in re.findall(r'(\d+)(\S)', cigar):
            num = int(num)
            if type == 'H' or type == 'S':
                if first_thing:
                    self.qStart += num
            elif type == 'I':
                q_aln_len += num
                self.num_ins += num
            elif type in ('M', '=', 'X'):
                cur_end += num
                q_aln_len += num
                self.num_mat_or_sub += num
            elif type == 'D':
                cur_end += num
                self.num_del += num
            elif type == 'N':  # junction, make a new segment
                if num > 0:
                    if cur_start != cur_end:
                        segments.append(Interval(cur_start, cur_end))
                    cur_start = cur_end + num
                    cur_end = cur_start
            else:
                raise Exception("Unrecognized cigar character {0}!".format(type))
            first_thing = False
        if cur_start != cur_end:
            segments.append(Interval(cur_start, cur_end))
        self.qEnd = self.qStart + q_aln_len
        return segments

    @classmethod
    def parse_sam_flag(self, flag):
        """
        Heng Li's SAM https://samtools.github.io/hts-specs/SAMv1.pdf
        1 -- read is one of a pair
        2 -- alignment is one end of proper PE alignment          (IGNORE)
        4 -- read has no reported alignments                      (IGNORE)
        8 -- read is one of a pair and has no reported alignments (IGNORE)
        16 -- reverse ref strand
        32 -- other mate is aligned to ref strand
        64 -- first mate in pair
        128 -- second mate in pair
        256 -- not primary alignment
        512 -- not passing filters
        1024 -- PCR or optical duplicate
        2048 -- supplementary alignment
        Return: SAMflag
        """
        PE_read_num = 0
        strand = '+'
        if flag >= 2048:  # supplementary alignment
            flag -= 2048
        if flag >= 1024:  # PCR or optical duplicate, should never see this...
            flag -= 1024
        if flag >= 512:  # not passing QC, should never see this
            flag -= 512
        if flag >= 256:  # secondary alignment, OK to see this if option given in BowTie
            flag -= 256
        if flag >= 128:
            PE_read_num = 2
            flag -= 128
        elif flag >= 64:
            PE_read_num = 1
            flag -= 64
        if flag >= 32:
            flag -= 32
        if flag >= 16:
            strand = '-'
            flag -= 16
        if flag >= 8:
            flag -= 8
        if flag >= 4:
            flag -= 4
        if flag >= 2:
            flag -= 2
        assert flag == 0 or flag == 1
        is_paired = flag == 1
        return SAMRecord.SAMflag(is_paired, strand, PE_read_num)


class GMAPSAMReader(SAMReader):
    def __next__(self):
        while True:
            line = self.f.readline().strip()
            if len(line) == 0:
                raise StopIteration
            if not line.startswith('@'):  # header can occur at file end if the SAM was sorted
                break
        return GMAPSAMRecord(line)


class GMAPSAMRecord(SAMRecord):
    def process(self, record_line):
        """
        SAM files from pbalign.py have following optional fields:
            XS: 1-based qStart, XE: 1-based qEnd, XQ: query length, NM: number of non-matches
    
        0. qID
        1. flag
        2. sID
        3. 1-based offset sStart
        4. mapping quality (ignore)
        5. cigar
        6. name of ref of mate alignment (ignore)
        7. 1-based offset sStart of mate (ignore)
        8. inferred fragment length (ignore)
        9. sequence (ignore)
        10. read qual (ignore)
        11. optional fields
        """
        raw = record_line.split('\t')
        self.qID = raw[0]
        self.sID = raw[2]
        if self.sID == '*':  # means no match! STOP here
            return
        self.sStart = int(raw[3]) - 1
        self.cigar = raw[5]
        self.qLen = len(raw[10])
        self.segments = self.parse_cigar(self.cigar, self.sStart)
        self.sEnd = self.segments[-1].end
        self.flag = SAMRecord.parse_sam_flag(int(raw[1]))  # strand can be overwritten by XS:A flag
        self._flag_strand = self.flag.strand  # serve as backup for debugging

        for x in raw[11:]:
            if x.startswith('NM:i:'):  # number of non-matches
                self.num_nonmatches = int(x[5:])
                self.identity = 1. - (self.num_nonmatches * 1. / (self.num_del + self.num_ins + self.num_mat_or_sub))
            elif x.startswith('XS:A:'):  # strand information
                _s = x[5:]
                if _s != '?':
                    self._flag_strand = self.flag.strand  # serve as backup for debugging
                    self.flag = SAMRecord.SAMflag(self.flag.is_paired, _s, self.flag.PE_read_num)
            elif x.startswith('ts:A:'):  # mm2 strand information
                _s = x[5:]
                if _s != '?':
                    if _s == '-':
                        _oposite = '+' if self.flag.strand == '-' else '-'
                        self.flag = SAMRecord.SAMflag(self.flag.is_paired, _oposite, self.flag.PE_read_num)
                    self._flag_strand = self.flag.strand  # serve as backup for debugging

        if self.flag.strand == '-' and self.qLen is not None:
            self.qStart, self.qEnd = self.qLen - self.qEnd, self.qLen - self.qStart

        if self.qLen is not None:
            self.qCoverage = (self.qEnd - self.qStart) * 1. / self.qLen


def convert_sam_rec_to_gff3_rec(r, source):
    """
    :param r: GMAPSAMRecord record
    :param qid_seen: list of qIDs processed so far -- if redundant, we have to put a unique suffix
    :return SeqRecord ready to be written as GFF3
    """
    if r.sID == '*':
        print("Skipping {} because unmapped.".format(r.qID), file=sys.stderr)
        return None
    seq = Seq('A')
    rec = SeqRecord(seq, r.sID)
    strand = 1 if r.flag.strand == '+' else -1
    seen_ts = False

    for x in r.record_line.split('\t')[11:]:
        if x.startswith('NH:i:'):
            seen_ts = True
        elif x.startswith('ts:A:'):  # mm2 strand information
            seen_ts = True
            _s = x[5:]
            if _s == '?':
                strand = None
        elif x.startswith('XS:A:'):  # gmap strand information
            _s = x[5:]
            if _s != '?':
                seen_ts = True
                _s = x[5:]
                if _s == '?':
                    strand = None

    if len(r.segments) == 1 and not seen_ts:
        strand = None
    if not seen_ts:
        strand = None

    indels = r.num_ins + r.num_del
    mismatches = r.num_nonmatches
    matches = r.num_mat_or_sub - r.num_nonmatches

    gene_qualifiers = {"source": source, "ID": r.qID, "Name": r.qID}  # for gene record
    mRNA_qualifiers = {"source": source, "ID": r.qID + '.mRNA', "Name": r.qID + '.mRNA', "Parent": r.qID,
                       "coverage": "{0:.1f}".format(r.qCoverage * 10 ** 2) if r.qCoverage is not None else "NA",
                       "identity": "{0:.1f}".format(r.identity * 10 ** 2),
                       "matches": matches, "mismatches": mismatches, "indels": indels}

    # gene line, one per record
    top_feature = SeqFeature(FeatureLocation(r.sStart, r.sEnd), type="gene", strand=strand, qualifiers=gene_qualifiers)
    # mRNA line, one per record
    top_feature.sub_features = []
    top_feature.sub_features = [
        SeqFeature(FeatureLocation(r.sStart, r.sEnd), type="mRNA", strand=strand, qualifiers=mRNA_qualifiers)]
    top_feature.sub_features[0].sub_features = []

    # exon lines, as many exons per record
    for i, e in enumerate(r.segments) if strand == 1 else enumerate(reversed(r.segments)):
        _id = "{0}.exon{1}".format(r.qID, i + 1)
        exon_qual = {"source": source, "ID": _id, "Name": _id}
        top_feature.sub_features[0].sub_features.append(
            SeqFeature(FeatureLocation(e.start, e.end), type="exon", strand=strand, qualifiers=exon_qual))
    rec.features = [top_feature]
    return rec


def main():
    parser = ArgumentParser("Convert SAM to GFF3 format")
    parser.add_argument("-i", "--sam_filename")
    parser.add_argument("-o", "--gff3_output")
    parser.add_argument("-s", "--source", required=True, help="source name for gff3 file")

    args = parser.parse_args()

    if args.sam_filename and not args.sam_filename.endswith('.sam'):
        print("Only accepts files ending in .sam. Abort!", file=sys.stderr)
        sys.exit(-1)
    if not args.sam_filename:
        input_file_handle = sys.stdin
        has_header = False
    else:
        input_file_handle = open(args.sam_filename, "r")
        has_header = True

    if not args.gff3_output:
        output_gff3 = sys.stdout
    else:
        output_gff3 = open(args.gff3_output, 'w')

    writer = GFF3Writer(output_gff3)
    for r0 in GMAPSAMReader(input_file_handle, has_header):
        rec = convert_sam_rec_to_gff3_rec(r0, args.source)
        if rec is not None:
            writer.write(rec)

    if args.gff3_output:
        print("Output written to {0}.".format(args.gff3_output), file=sys.stderr)


if __name__ == "__main__":
    try:
        main()
    except (BrokenPipeError, IOError):
        sys.stderr.close()
