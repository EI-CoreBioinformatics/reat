
#+STARTUP: lognotedone
For functionality:
 1 Do it
 2 Do it well
 3 Do it fast

For speed:
  1 Get it right.
  2 Test it's right.
  3 Profile if slow.
  4 Optimise.
  5 Repeat from 2.

For cleanliness:
  Start refactoring from the right (inner most section)

* Tasks
** TODO DS review 1
*** DONE Sanitite output the results (reference + index)
    CLOSED: [2020-05-11 Mon 12:04]
    - CLOSING NOTE [2020-05-11 Mon 12:04]
*** DONE Merge bams before stringtie instead of using stringtie merge after assembly
    CLOSED: [2020-05-11 Mon 14:32]
    - CLOSING NOTE [2020-05-11 Mon 14:32] \\
      It seems a better option to merge assemblies rather than bams, so this was implemented.
      There will also be no merge calls for single alignment samples, in case there are artifacts when
      running merge unnecesarily.
*** DONE Fix bug in portcullis grouping
    CLOSED: [2020-05-11 Mon 12:04]
    - CLOSING NOTE [2020-05-11 Mon 12:04]
*** DONE Add *fail* files to output
    CLOSED: [2020-05-11 Mon 13:50]
    - CLOSING NOTE [2020-05-11 Mon 13:50] \\
      Done, this is done taking the results of the Portcullis Full task and combining the results in a Merge task for the pass files and another for the fail files
*** TODO Group and generate basic + summary stats on the alignment results
**** DONE Individual statistics and plots
     CLOSED: [2020-05-11 Mon 13:52]
     - CLOSING NOTE [2020-05-11 Mon 13:52]
**** TODO Summary statistics, per sample and overall
*** TODO Read and incorporate stats from GENANNO-466
**** DONE Generate stats for the assemblies
     CLOSED: [2020-05-11 Mon 13:53]
     - CLOSING NOTE [2020-05-11 M
**** DONE Generate Mikado stats
     CLOSED: [2020-05-11 Mon 13:53]
     - CLOSING NOTE [2020-05-11 Mon 13:5
**** TODO Generate summary stats for the assemblies
** TODO Generate a main "running" script that will tie everything together with CLI + input file validation
** TODO Start thinking about a good installation procedure for all the non-dependency requirements
*** TODO Create a dockerfile with all the dependencies and it's installation
*** TODO Create a singularity definition file with all the dependencies and it's installation
** TODO Add "extra" options for each command
Will need to consider how to do this properly, seems like sub workflows 
might hide some of the optional parameters if they are not mapped properly from the calling wf

The optional input parameters need to be mapped to the calling WF input parameters, 
this will require a lot of work, need to check if there are alternatives
** TODO Collect a list of all flavours of gff3 used in the pipeline and simplify it
At the moment there's no collated list.
** TODO Write documentation for the pipeline
*** TODO Code docs
*** TODO Document all input variables with meta tags
*** DONE Write a schema for interactively generating input and input validation
    CLOSED: [2020-04-24 Fri 11:46]
    - CLOSING NOTE [2020-04-24 Fri 11:46] \\
      Fixed in 2eb46137414d2b0099f8711759353224b12edaa2
**** DONE Start writing a json schema for all WF inputs
     CLOSED: [2020-04-24 Fri 11:46]
     - CLOSING NOTE [2020-04-24 Fri 11:46]
 Try as much as possible to reuse the parts
**** DONE Prodigal/Transdecoder genetic code option needs to be handled here
     CLOSED: [2020-04-24 Fri 11:46]
     - CLOSING NOTE [2020-04-24 Fri 11:46]
*** DONE Usage docs
    CLOSED: [2020-04-24 Fri 11:45]
    - CLOSING NOTE [2020-04-24 Fri 11:45] \\
      Fixed in abe2ef40a
*** DONE Diagrams
    CLOSED: [2020-03-06 Fri 12:12]
    - CLOSING NOTE [2020-03-06 Fri 12:12] \\
      Need improvement
There's a draft diagram next to each wdl file generated by womtools but they are not great as they do not include inputs and outputs
** TODO Implement the Genome Threader pipeline
   DEADLINE: <2020-02-28 Fri> SCHEDULED: <2020-02-17 Mon>
** TODO Consider EDTA for repeat modelling and masking
Consider it instead of the slow and restrictive RepeatMasker and Modeller
See link [[https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1905-y]]
** DONE Propagate the "constraints" runtime variable value to other tasks in the pipeline
   CLOSED: [2020-04-30 Thu 12:17]
   - CLOSING NOTE [2020-04-30 Thu 12:17]
** DONE Allow user to merge samples for portcullis runs
   CLOSED: [2020-04-24 Fri 11:44]
   - CLOSING NOTE [2020-04-24 Fri 11:44] \\
     Fixed in commit 18cf2f4
This task requires https://broadworkbench.atlassian.net/browse/BA-4219 to be fixed before being able to complete it
*** TODO Check that the strandedness of samples to join are compatible
*** TODO Check that all samples are referenced for this step.
** DONE Run tests on scaffold6 region
   CLOSED: [2020-04-08 Wed 17:35]
   - CLOSING NOTE [2020-04-08 Wed 17:35] \\
     Tests have been ran with the results sent to DS, differences between DS and this are:
     
     No portcullis merging of samples per strandness (this is pending on some implementation issues of cromwell's WDL stdlib).
     Paralelised TransDecoder vs Prodigal
     Homology mappings were done using blast (default parameters) compared to diamond
organ_WLMPM.sort_scaffold_6 is 1.8 GB
organ_WMPM.sort_scaffold_6 is 3.0 GB
The rest are aroung 100 MB
polished.fastq is 9.1 MB

** DONE Move the genome indexing to the short read alignment workflow
   CLOSED: [2020-04-03 Fri 13:38]
   - CLOSING NOTE [2020-04-03 Fri 13:38] \\
     Done
** DONE Collapse output of mikado prepare before serialize and pick
   CLOSED: [2020-03-30 Mon 15:02]
   - CLOSING NOTE [2020-03-30 Mon 15:02] \\
     Done, see Luca's reply for issue-270 in Mikado
This could be implemented within mikado or using gffread and then filtering mikado's input
Check if this could be done by rerunning prepare after using gffread?

** DONE Bubble up all the parameters for the different tasks and workflows
   CLOSED: [2020-03-30 Mon 15:01]
   - CLOSING NOTE [2020-03-30 Mon 15:01]
This is required for the main workflow to allow user overriding
*** DONE Unify genetic codes for mikado workflow
    CLOSED: [2020-03-19 Thu 10:26]
    - CLOSING NOTE [2020-03-19 Thu 10:26] \\
      orf_caller/*.cdt files created with a direct equivalence of "codon_table" to int
      sadly, Transdecoder only supports a subset of what Prodigal can support
      which means there's no 1-to-1 mapping for all possible options, this needs to be
      handled during the configuration generator
*** DONE Pass HPC resource requirements
    CLOSED: [2020-03-18 Wed 16:40]
    - CLOSING NOTE [2020-03-18 Wed 16:40] \\
      Done on commit c0874cd
** DONE Add a filter stage after the LR assemblies using filter_gmap_hardFilter_v0.1.pl
   CLOSED: [2020-03-25 Wed 16:27]
   - CLOSING NOTE [2020-03-25 Wed 16:27]
** DONE Check how if possible to run most of the analysis that can be done per sample instead of waiting when not necessary
   CLOSED: [2020-03-20 Fri 10:07]
   - CLOSING NOTE [2020-03-20 Fri 10:07] \\
     All tasks are separated and merged at the right stage, there's a natural division at the mikado stage
     which is being used to separate all alignment related tasks in the workflow from the mikado runs.
This is for the short read samples but maybe also for the long reads
** DONE Check if it's possible to remove "magic/libmagic" dependency from mikado (wish list)
   CLOSED: [2020-03-20 Fri 10:02]
   - CLOSING NOTE [2020-03-20 Fri 10:02] \\
     Being merged to mikado
** DONE Simplify BLAST+ output formats
   CLOSED: [2020-03-19 Thu 11:37]
   - CLOSING NOTE [2020-03-19 Thu 11:37] \\
     Almost done with Luca + fixes to diamond by bbuchfink
Luca's efforts on Mikado issue 280 are a great step in this direction.
** DONE Should the portcullis junctions be used for LR mapping if available?
   CLOSED: [2020-03-19 Thu 11:36]
   - CLOSING NOTE [2020-03-19 Thu 11:36] \\
     Yes they should and now they are incorporated
** DONE Test transdecoder + alignments
   CLOSED: [2020-03-17 Tue 11:49]
   - CLOSING NOTE [2020-03-17 Tue 11:49] \\
     Tests done, but the results are slightly different between the original and the chunked version,
     this is mostly to do with the chunking at the orf calling stage, might be worth exploring doing this
     chunking after that stage for the evaluation of the predict stage as it should make results consistent
     across chunked and original.
Now that the chunking is finished, the protein alignments can be tested for the 
start codon refinement steps, also the results need to be validated against a non-chunked run
*** DONE Fix hexamer.scores.
    CLOSED: [2020-03-17 Tue 11:48]
    - CLOSING NOTE [2020-03-17 Tue 11:48] \\
      The scores are different because of differences in the sequences that were selected from the top500. These differences are down to the order in which they appeared in the input files (chunked version has no inherent order as it depends on what is executed first).
      
      The results on local testing are 100% reproducible but might not be in an HPC environment.
Seems like there's an off by one somewhere before this point, maybe there are extra sequences
or some filtering is not working properly before this point. The scores look quite similar but there
are more kmers in the "chunked" version which indicates the error
** DONE Generate "chunks" for transdecoder
   CLOSED: [2020-03-12 Thu 22:29]
   - CLOSING NOTE [2020-03-12 Thu 22:29] \\
     Most of the tasks are done, missing a multi file merge for the transcripts and the counts of the nucleotide frequencies
The input to both transdecoder and prodigal could be "chunked" to increase parallelism... Check if this can be natively supported
or if the final results need to be merged somehow.

Chat w DS <2020-03-10 Tue 16:52> a single step for both Transdecoder + Prodigal to select a training set.
Transdecoder will need to be re-implemented within the WF to accommodate for chunking of the prediction and long_orf calling
Prodigal will be ran in two steps once for training using a pre-selection from mikado_prepare output and once for classifying all transcripts
Transdecoder will be reworked within WF to run on different steps

Collect training information
Generate all longest_orfs
Predict best orf using training information
*** DONE Write down how TransDecoder works for translating into the WF
    CLOSED: [2020-03-11 Wed 15:58]
    - CLOSING NOTE [2020-03-11 Wed 15:58] \\
      All steps of transdecoder have been analysed and annotated
**** LongOrfs
Decompress transcript sequences
Compute base probabilities ACTG output BASE \t COUNT \t 0.3f RATIO
Calculate the longest_orfs
Overall: Longest orfs just calculates the longest orf for each transcript and generates a probability table for each nucleotide
This whole step can be done in a scatter region
**** Predict
Decompresses the transcripts file
Get up to topORFsTrain*10 longest transcripts
Excludes similar proteins using presence/absence of 5mers

Gets up to topORFsTrain from the reduced set (no similar proteins) (top_cds_file)
Compute a table relating GC content to a minimum ORF length filter (hashmap RETAIN_LONG_ORFS_MIN_LENGTH)
Score the top_cds_file kmers (hexamers) for markov model
Score all entries in the top_cds_file using hexamers (cds_scores_file)
Select orfs from the "longorfs.gff3" output (can be done in a scatter) using cds_scores_file, RETAIN_LONG_ORFS_MIN_LENGTH  (best_candidates.gff3)

Refine start codons
  train a PWM model using transcripts top_cds_file (Sequential, small enough not to be a problem)
  Train atg_PWM:
    Builds ATG PWM from selected transcripts + "all other transcripts" which it only uses to recover the sequences of the selected transcripts (top500  longest ORFS)
    From this point onward it only uses the data collected from the previous step.
    Use the PWM trained model to refine the start codons of the rest of the transcripts (this part can be paralelised)
*** DONE Subdivide Prodigal in the WF
    CLOSED: [2020-03-10 Tue 22:40]
    - CLOSING NOTE [2020-03-10 Tue 22:40] \\
      Meeting with DS 2020-03-10, decided it's probably not necessary as this process should be fast enough as is
*** DONE Check if output of mikado prepare is biased (sorted according to fasta or similar)
    CLOSED: [2020-03-10 Tue 14:42]
    - CLOSING NOTE [2020-03-10 Tue 14:42] \\
      The transcripts come out sorted from the preparation process... Ideally this would be sampled for training and chunked for prediction
** DONE Map all mikado outputs/potential outputs (noLQ and all)
   CLOSED: [2020-03-11 Wed 12:46]
   - CLOSING NOTE [2020-03-11 Wed 12:46] \\
     All mikado outputs mapped to an optional output parameter for the mikado WF
** DONE Check if it's best to run all the homology and orf_calling blasts separate to the Mikado WF
   CLOSED: [2020-03-11 Wed 12:47]
   - CLOSING NOTE [2020-03-11 Wed 12:47] \\
     Chat with DS <2020-03-11 Wed 12:47>, yes this is not only useful but would also avoid repeating mappings
It seems like some of the tasks will have repeated inputs, maybe it's worth running separately and then merging everything to avoid
repeating work... This is a bit related to how the Homology input is defined Mikado issue 280 becomes even more critical.
** DONE Test main workflow end-to-end and upload results to "apollo server"
   CLOSED: [2020-03-09 Mon 15:27]
   - CLOSING NOTE [2020-03-09 Mon 15:27] \\
     http://jira.earlham.ac.uk/browse/GENANNO-468 comment defines the outputs of an initial end-to-end test.
     This test needs to be reran on the HPC and all options should be verified are working as expected, estimating it as low priority.
** DONE Install gnuplot on singularity container
   CLOSED: [2020-03-03 Tue 17:04] SCHEDULED: <2020-03-03 Tue>
   - CLOSING NOTE [2020-03-03 Tue 17:04] \\
     Installed and deployed... Tests running on HPC. ei_annotation-0.0.3 contains all binaries required for the main.wdl workflow
** DONE Fix the main workflow for the first integrated run
   CLOSED: [2020-03-03 Tue 10:17]
   - CLOSING NOTE [2020-03-03 Tue 10:17] \\
     All workflows output finished products (AlignedSample, AssembledSample) which are used by higher level workflows
The main workflow needs to pass assembled samples to mikado, the long assembler workflow does not produce these
** DONE Setup mikado run
   CLOSED: [2020-03-02 Mon 19:41]

   - CLOSING NOTE [2020-03-02 Mon 19:41] \\
     Done, mikado run finished correctly. Had to generate a singularity definition file and create a container with all binaries required for the WF for this to work. Changes are committed in the repo
    "wf_align.LQ_gff":
    
[
{"name": "A01_1",
"assembly": "/ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_align/cromwell-executions/wf_align/fa7d6c9d-7a99-4dad-bee3-13a267cb7128/call-LQ_assembly/wf_assembly_long/1f5c371e-5762-40a9-9321-b0586ad534c0/call-stringtie_long/shard-0/execution/r54053_20170914_095520_1_A01-m54053_170914_101735.minimap2.stringtie.gff",
"strand": "fr-firststrand"
},
{"name": "A01_2",
"assembly":
"/ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_align/cromwell-executions/wf_align/fa7d6c9d-7a99-4dad-bee3-13a267cb7128/call-LQ_assembly/wf_assembly_long/1f5c371e-5762-40a9-9321-b0586ad534c0/call-stringtie_long/shard-1/execution/r54053_20170915_105219_1_A01-m54053_170915_110119.minimap2.stringtie.gff",
"strand": "fr-firststrand"
},
{"name": "B01",
"assembly":
"/ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_align/cromwell-executions/wf_align/fa7d6c9d-7a99-4dad-bee3-13a267cb7128/call-LQ_assembly/wf_assembly_long/1f5c371e-5762-40a9-9321-b0586ad534c0/call-stringtie_long/shard-2/execution/r54053_20170915_105219_2_B01-m54053_170915_210825.minimap2.stringtie.gff",
"strand": "fr-firststrand"
},
{"name": "C01",
"assembly":
"/ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_align/cromwell-executions/wf_align/fa7d6c9d-7a99-4dad-bee3-13a267cb7128/call-LQ_assembly/wf_assembly_long/1f5c371e-5762-40a9-9321-b0586ad534c0/call-stringtie_long/shard-3/execution/r54053_20170915_105219_3_C01-m54053_170916_072810.minimap2.stringtie.gff",
"strand": "fr-firststrand"
}
],

    "wf_align.HQ_gff": 
[
{"name": "CCS",
"assembly": "/ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_align/cromwell-executions/wf_align/fa7d6c9d-7a99-4dad-bee3-13a267cb7128/call-HQ_assembly/wf_assembly_long/58ddcfcc-c27a-4c66-8229-9ad62a812511/call-gffread_merge/shard-0/execution/CCS.minimap2.gffread_merge.gff",
"strand": "fr-firststrand"
},
{"name": "Polished",
"assembly": "/ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_align/cromwell-executions/wf_align/fa7d6c9d-7a99-4dad-bee3-13a267cb7128/call-HQ_assembly/wf_assembly_long/58ddcfcc-c27a-4c66-8229-9ad62a812511/call-gffread_merge/shard-1/execution/polished.minimap2.gffread_merge.gff",
"strand": "fr-firststrand"
}
],

    "wf_align.SR_gff":
[{
      "strand": "fr-firststrand",
      "assembly": "/ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_align/cromwell-executions/wf_align/fa7d6c9d-7a99-4dad-bee3-13a267cb7128/call-wf_assembly_short/wf_assembly_short/ced605d7-d4f4-474f-8a0d-58cd07f0767f/call-Merge/shard-0/execution/Ara.hisat.stringtie.gtf",
      "name": "Ara.hisat.stringtie"
    }, {
      "strand": "fr-firststrand",
      "assembly": "/ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_align/cromwell-executions/wf_align/fa7d6c9d-7a99-4dad-bee3-13a267cb7128/call-wf_assembly_short/wf_assembly_short/ced605d7-d4f4-474f-8a0d-58cd07f0767f/call-Scallop/shard-0/execution/Ara.hisat.scallop.gtf",
      "name": "Ara.hisat.scallop"
    }],

  "wf_align.clean_reference_index": {
    "fasta": "/ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_align/cromwell-executions/wf_align/fa7d6c9d-7a99-4dad-bee3-13a267cb7128/call-wf_sanitize/wf_sanitize/1b1badcc-a12e-4798-8d47-aeaa94f00f04/call-IndexFasta/execution/reference.san.fasta",
    "fai": "/ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_align/cromwell-executions/wf_align/fa7d6c9d-7a99-4dad-bee3-13a267cb7128/call-wf_sanitize/wf_sanitize/1b1badcc-a12e-4798-8d47-aeaa94f00f04/call-IndexFasta/execution/reference.san.fasta.fai"
  },

  "scoring_file": /hpc-home/yanesl/workarea/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_mikado/plant.yml

** DONE Add Biological replicate level to the samples
   CLOSED: [2020-02-24 Mon 11:21]
   - CLOSING NOTE [2020-02-24 Mon 11:21] \\
     This is done and tests are currently executing.
Currently all the samples are treated as biological given that they can only take a single input file or pair of files.
Separating biological from technical samples enables the user to assign several input file or pairs of files under the same
sample name.
i.e, currently paired_samples input looks like this:
    "wf_align.paired_samples": [
        {
            "name": "Ara1",
            "strand": "fr-firststrand",
            "R1": "/hpc-home/yanesl/workarea/Projects/CB-GENANNO-468_REAT-transcriptome_module/Reads/Ara1_R1.fastq.gz",
            "R2": "/hpc-home/yanesl/workarea/Projects/CB-GENANNO-468_REAT-transcriptome_module/Reads/Ara1_R2.fastq.gz"
        },
        {
            "name": "Ara2",
            "strand": "fr-firststrand",
            "R1": "/hpc-home/yanesl/workarea/Projects/CB-GENANNO-468_REAT-transcriptome_module/Reads/Ara2_R1.fastq.gz",
            "R2": "/hpc-home/yanesl/workarea/Projects/CB-GENANNO-468_REAT-transcriptome_module/Reads/Ara2_R2.fastq.gz"
        }
    ]
In reality these are technical replicates from the same biological sample, so it should look like this:
    "wf_align.paired_samples": [
        {
            "biological_sample_name": "Ara",
	    "technical_samples": [
	        {
		"name": "Ara1",
		"strand": "fr-firststrand",
		"R1": "/hpc-home/yanesl/workarea/Projects/CB-GENANNO-468_REAT-transcriptome_module/Reads/Ara1_R1.fastq.gz",
		"R2": "/hpc-home/yanesl/workarea/Projects/CB-GENANNO-468_REAT-transcriptome_module/Reads/Ara1_R2.fastq.gz"
		},
		{
		"name": "Ara2",
		"strand": "fr-firststrand",
		"R1": "/hpc-home/yanesl/workarea/Projects/CB-GENANNO-468_REAT-transcriptome_module/Reads/Ara2_R1.fastq.gz",
		"R2": "/hpc-home/yanesl/workarea/Projects/CB-GENANNO-468_REAT-transcriptome_module/Reads/Ara2_R2.fastq.gz"
		},
	    ]
	}
    ]

Finally, all the technical sample alignments can be combined into a single assembly, idem for the long read samples
** DONE Run a first test of the alignment+assembly workflow with all the input types
   CLOSED: [2020-02-17 Mon 16:18]
   - CLOSING NOTE [2020-02-17 Mon 16:18] \\
     Running should be OK. Had some issues but is mostly to do with the environment setup (some indexing tasks failed) rather than something more fundamental to the commands being executed or the resources being requested.
Has started running <2020-02-17 Mon 15:12>, seems like the HQ will fail due to a typo in the command (gzcat -> zcat).
Once the currently running wf has completed (possibly failed) rerun with the corrected command (have already done so)
** DONE Define the compute required for each task and make it customisable
   CLOSED: [2020-02-17 Mon 15:10]
   - CLOSING NOTE [2020-02-17 Mon 15:10] \\
     The compute requirements are now present in the configuration and used for the task's runtime
** DONE Add collapse/assemble steps for long read samples
   CLOSED: [2020-02-14 Fri 12:10]
Take the output BAM/SAM and send them right through to the LR_assembly workflow the output of this will be gff3
   DEADLINE: <2020-02-07 Fri> SCHEDULED: <2020-02-03 Mon>
   - CLOSING NOTE [2020-02-10 Mon 18:07] \\
     The output of sam2gff.py matches both gmap and minimap2 output correctly as tested by comparing:
     
     vimdiff pinfish_gffread_mm2.gtf mm2_sam2gff_no0N_gffread.gtf
     vimdiff gene_noCDS_nScore.gtf gmap_samse_n1_sam2gff.gtf
     
     This can be used as a great starting point for further development of SAM2GFF output from any of the alignment tools
*** DONE Checking sam/gene_gff is the same
    CLOSED: [2020-02-05 Wed 17:20]
    - CLOSING NOTE [2020-02-05 Wed 17:20] \\
      They are the same
**** DONE They are not the same this is due to the quality of some of the read's alignments.
     CLOSED: [2020-02-05 Wed 17:19]
     - CLOSING NOTE [2020-02-05 Wed 17:19] \\
       I needed to filter the outputs as the cross comparison of different reads in the same region was skewing the results
Command line:
/Users/yanesl/Envs/ei-annotation/bin/mikado compare -r gene.gff3 -p samse_n1.gff3
634 reference RNAs in 634 genes
499 predicted RNAs in  499 genes
--------------------------------- |   Sn |   Pr |   F1 |
                        Base level: 79.39  94.30  86.21
            Exon level (stringent): 48.94  56.12  52.28
              Exon level (lenient): 49.89  56.99  53.21
                 Splice site level: 51.06  57.10  53.91
                      Intron level: 53.90  58.75  56.22
                 Intron level (NR): 47.15  53.11  49.95
                Intron chain level: 42.00  52.51  46.67
           Intron chain level (NR): 40.14  50.90  44.89
      Transcript level (stringent): 37.54  47.70  42.01
  Transcript level (>=95% base F1): 43.38  54.31  48.23
  Transcript level (>=80% base F1): 43.69  54.31  48.42
         Gene level (100% base F1): 37.54  47.70  42.01
        Gene level (>=95% base F1): 43.38  54.31  48.23
        Gene level (>=80% base F1): 43.69  54.31  48.42

#   Matching: in prediction; matched: in reference.

            Matching intron chains: 241
             Matched intron chains: 244
   Matching monoexonic transcripts: 30
    Matched monoexonic transcripts: 33
        Total matching transcripts: 271
         Total matched transcripts: 277

          Missed exons (stringent): 2737/5360  (51.06%)
           Novel exons (stringent): 2051/4674  (43.88%)
            Missed exons (lenient): 2612/5213  (50.11%)
             Novel exons (lenient): 1963/4564  (43.01%)
                    Missed introns: 2391/4524  (52.85%)
                     Novel introns: 1883/4016  (46.89%)

       Missed transcripts (0% nF1): 90/634  (14.20%)
        Novel transcripts (0% nF1): 22/499  (4.41%)
             Missed genes (0% nF1): 90/634  (14.20%)
              Novel genes (0% nF1): 22/499  (4.41%)

**** DONE Filter the alignments and compare again after having collapsed the gff3 output of GMap
     CLOSED: [2020-02-05 Wed 17:19]
     - CLOSING NOTE [2020-02-05 Wed 17:19] \\
       Gff3 filtering
       
       
       Command line:
       /Users/yanesl/Envs/ei-annotation/bin/mikado compare -r gene_c70.gff3 -p gmap_samse_n1_sam2gff_c70.gff3
       6 reference RNAs in 6 genes
       6 predicted RNAs in  6 genes
       --------------------------------- |   Sn |   Pr |   F1 |
                               Base level: 100.00  100.00  100.00
                   Exon level (stringent): 100.00  97.47  98.72
                     Exon level (lenient): 100.00  97.47  98.72
                        Splice site level: 100.00  97.18  98.57
                             Intron level: 97.26  94.67  95.95
                        Intron level (NR): 97.10  94.37  95.71
                       Intron chain level: 60.00  60.00  60.00
                  Intron chain level (NR): 60.00  60.00  60.00
             Transcript level (stringent): 66.67  66.67  66.67
         Transcript level (>=95% base F1): 66.67  66.67  66.67
         Transcript level (>=80% base F1): 66.67  66.67  66.67
                Gene level (100% base F1): 66.67  66.67  66.67
               Gene level (>=95% base F1): 66.67  66.67  66.67
               Gene level (>=80% base F1): 66.67  66.67  66.67
       
       #   Matching: in prediction; matched: in reference.
       
                   Matching intron chains: 3
                    Matched intron chains: 3
          Matching monoexonic transcripts: 1
           Matched monoexonic transcripts: 1
               Total matching transcripts: 4
                Total matched transcripts: 4
       
                 Missed exons (stringent): 0/77  (0.00%)
                  Novel exons (stringent): 2/79  (2.53%)
                   Missed exons (lenient): 0/77  (0.00%)
                    Novel exons (lenient): 2/79  (2.53%)
                           Missed introns: 2/69  (2.90%)
                            Novel introns: 4/71  (5.63%)
       
              Missed transcripts (0% nF1): 0/6  (0.00%)
               Novel transcripts (0% nF1): 0/6  (0.00%)
                    Missed genes (0% nF1): 0/6  (0.00%)
                     Novel genes (0% nF1): 0/6  (0.00%)
       
       The results are comparable, can continue development
Gmap -> gff3 -> filter? -> collapse vs Gmap -> sam -> filter -> gff3 -> collapse

*** DONE Check minimap2 output, filter and generate gff3
    CLOSED: [2020-02-05 Wed 17:22]

    - CLOSING NOTE [2020-02-05 Wed 17:22] \\
      Initial output not looking great:
      
      Command line:
      /Users/yanesl/Envs/ei-annotation/bin/mikado compare -r gene_c70.gff3 -p mm2_sam2gff_c70.gff3
      6 reference RNAs in 6 genes
      18 predicted RNAs in  18 genes
      --------------------------------- |   Sn |   Pr |   F1 |
                              Base level: 41.96  16.20  23.38
                  Exon level (stringent): 20.78  12.80  15.84
                    Exon level (lenient): 22.37  13.71  17.00
                       Splice site level: 31.16  20.09  24.43
                            Intron level: 27.40  18.69  22.22
                       Intron level (NR): 28.99  18.69  22.73
                      Intron chain level: 0.00  0.00  0.00
                 Intron chain level (NR): 0.00  0.00  0.00
            Transcript level (stringent): 0.00  0.00  0.00
        Transcript level (>=95% base F1): 0.00  0.00  0.00
        Transcript level (>=80% base F1): 0.00  0.00  0.00
               Gene level (100% base F1): 0.00  0.00  0.00
              Gene level (>=95% base F1): 0.00  0.00  0.00
              Gene level (>=80% base F1): 0.00  0.00  0.00
      
      #   Matching: in prediction; matched: in reference.
      
                  Matching intron chains: 0
                   Matched intron chains: 0
         Matching monoexonic transcripts: 0
          Matched monoexonic transcripts: 0
              Total matching transcripts: 0
               Total matched transcripts: 0
      
                Missed exons (stringent): 61/77  (79.22%)
                 Novel exons (stringent): 109/125  (87.20%)
                  Missed exons (lenient): 59/76  (77.63%)
                   Novel exons (lenient): 107/124  (86.29%)
                          Missed introns: 49/69  (71.01%)
                           Novel introns: 87/107  (81.31%)
      
             Missed transcripts (0% nF1): 1/6  (16.67%)
              Novel transcripts (0% nF1): 12/18  (66.67%)
                   Missed genes (0% nF1): 1/6  (16.67%)
                    Novel genes (0% nF1): 12/18  (66.67%)
*** DONE Check what's going on with minimap2 output
    CLOSED: [2020-02-05 Wed 17:25]
    - CLOSING NOTE [2020-02-05 Wed 17:25] \\
| ref_id                  | ref_gene                | ccode | tid                    | gid               | tid_num_exons | ref_num_exons | n_prec | n_recall |  n_f1 | j_prec | j_recall |  j_f1 | e_prec | e_recall |  e_f1 | distance | location                |
| -                       | -                       | u     | SRR3655756.5500.mRNA   | SRR3655756.5500   |             2 | -             |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | -        | Chr4:2133241..2135652   |
| -                       | -                       | u     | SRR3655756.6001.mRNA   | SRR3655756.6001   |             4 | -             |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | -        | Chr4:13743708..13745360 |
| -                       | -                       | u     | SRR3655756.6419.mRNA   | SRR3655756.6419   |             4 | -             |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | -        | Chr4:14451474..14453802 |
| -                       | -                       | u     | SRR3655756.14660.mRNA  | SRR3655756.14660  |             5 | -             |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | -        | Chr4:2489483..2495668   |
| SRR3655756.24143.mrna1  | SRR3655756.24143.path1  | G     | SRR3655756.24143.mRNA  | SRR3655756.24143  |             2 | 1             |  88.16 |    100.0 | 93.71 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | 0        | Chr4:2718189..2719615   |
| -                       | -                       | u     | SRR3655756.25980.mRNA  | SRR3655756.25980  |            10 | -             |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | -        | Chr4:274308..278082     |
| SRR3655756.24143.mrna1  | SRR3655756.24143.path1  | X     | SRR3655756.26633.mRNA  | SRR3655756.26633  |             2 | 1             |  61.68 |    100.0 |  76.3 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | 0        | Chr4:2718190..2720098   |
| SRR3655756.100340.mrna1 | SRR3655756.100340.path1 | I     | SRR3655756.41017.mRNA  | SRR3655756.41017  |             4 | 11            |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | 0        | Chr4:15072818..16995817 |
| -                       | -                       | u     | SRR3655756.53262.mRNA  | SRR3655756.53262  |             2 | -             |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | -        | Chr4:11216971..11219121 |
| -                       | -                       | u     | SRR3655756.56262.mRNA  | SRR3655756.56262  |             9 | -             |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | -        | Chr4:222377..225062     |
| -                       | -                       | u     | SRR3655756.65070.mRNA  | SRR3655756.65070  |             1 | -             |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | -        | Chr4:161536..163007     |
| SRR3655756.100340.mrna1 | SRR3655756.100340.path1 | I     | SRR3655756.73036.mRNA  | SRR3655756.73036  |             4 | 11            |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | 0        | Chr4:15072818..16995817 |
| SRR3655756.100340.mrna1 | SRR3655756.100340.path1 | X     | SRR3655756.100340.mRNA | SRR3655756.100340 |            10 | 11            |  99.11 |    97.65 | 98.37 |  88.89 |     80.0 | 84.21 |   70.0 |    63.64 | 66.67 | 0        | Chr4:15072818..16995818 |
| SRR3655756.116361.mrna1 | SRR3655756.116361.path1 | X     | SRR3655756.113509.mRNA | SRR3655756.113509 |            10 | 22            |  92.89 |    43.55 |  59.3 |  66.67 |    29.27 | 40.68 |   40.0 |    18.18 |  25.0 | 0        | Chr4:11496965..11504675 |
| -                       | -                       | u     | SRR3655756.118271.mRNA | SRR3655756.118271 |            14 | -             |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | -        | Chr4:11447419..11450608 |
| SRR3655756.139158.mrna1 | SRR3655756.139158.path1 | j     | SRR3655756.139158.mRNA | SRR3655756.139158 |            19 | 18            |  96.13 |    96.35 | 96.24 |  69.44 |    73.53 | 71.43 |  57.89 |    61.11 | 59.46 | 0        | Chr4:242517..246736     |
| -                       | -                       | u     | SRR3655756.158074.mRNA | SRR3655756.158074 |             6 | -             |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 |    0.0 |      0.0 |   0.0 | -        | Chr4:17825253..17828176 |
| SRR3655756.160094.mrna1 | SRR3655756.160094.path1 | j     | SRR3655756.160094.mRNA | SRR3655756.160094 |            17 | 17            |  91.46 |    99.91 |  95.5 |  56.25 |    56.25 | 56.25 |  29.41 |    29.41 | 29.41 | 0        | Chr4:12662879..12667188 |
Seems like minimap2 lets more transcripts filter through, but the ones that are the same look correct

*** DONE Minimap2 is less prone to small "N" sections than GMAP generating "cleaner" gene models and higher mapping accuracy
    CLOSED: [2020-02-06 Thu 11:11]

    - CLOSING NOTE [2020-02-06 Thu 11:11]
[[file:Dropbox/EI/SW-Group/EI-annotation/lr_alignments/SRR3655756.5500_gmap_vs_mm2.png][Example of alignment -> gene model]]
*** DONE Finish fixing sam2gff for mm2 and gmap output
    CLOSED: [2020-02-07 Fri 19:05] SCHEDULED: <2020-02-10 Mon>
    - CLOSING NOTE [2020-02-07 Fri 19:05] \\
      Done! They all match now for mm2!!!!
There is hope, the coordinates between spliced_bam2gff and sam2gff match, only the transcript orientations are wrong, correcting them will allow using a single python script for both and all sam output
** DONE Setup the Myzus_persicae dataset for annotation in n82132
   CLOSED: [2020-02-11 Tue 15:04] SCHEDULED: <2020-02-11 Tue 11:00>
   - CLOSING NOTE [2020-02-11 Tue 15:04]
** DONE <2020-02-10 Mon> Run align_wf on EI HPC using noserver
   CLOSED: [2020-02-10 Mon 14:43]
   - CLOSING NOTE [2020-02-10 Mon 14:43]
*** DONE <2020-02-10 Mon 12:41> Define inputs
    CLOSED: [2020-02-10 Mon 14:43]
    - CLOSING NOTE [2020-02-10 Mon 14:43]
** DONE Create a subset of RNA reads mapping to CHR4 to test the pipeline
   CLOSED: [2020-01-08 Wed 16:49] SCHEDULED: <2020-01-08 Wed>
   :LOGBOOK:
   CLOCK: <2020-01-08 Wed 11:09>--<2020-01-08 Wed 16:52>
   :END:
** DONE Investigate why there's a failing query on Portcullis results
   CLOSED: [2020-01-08 Wed 17:49] SCHEDULED: <2020-01-08 Wed>
   - CLOSING NOTE [2020-01-08 Wed 17:49] \\
     Didn't find out why it was failing but could simple transform the in/out steps from Array[Array[File]] to Array[File] and then finally the filtered/merged File for each type of output

[INFO] [01/08/2020 11:53:55.839] [cromwell-system-akka.dispatchers.backend-dispatcher-243] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-6777c92e-2239-4a27-baf6-09c4931e2a58/WorkflowExecutionActor-6777c92e-2239-4a27-baf6-09c4931e2a58/6777c92e-2239-4a27-baf6-09c4931e2a58-SubWorkflowExecutionActor-SubWorkflow-portcullis:-1:1/66b01287-e0e4-4928-9e5f-864554e506b4-SubWorkflowActor-SubWorkflow-portcullis:-1:1/66b01287-e0e4-4928-9e5f-864554e506b4-EngineJobExecutionActor-portcullis.Filter:3:1/66b01287-e0e4-4928-9e5f-864554e506b4-BackendJobExecutionActor-portcullis.Filter:3:1/BackgroundConfigAsyncJobExecutionActor] BackgroundConfigAsyncJobExecutionActor [UUID(66b01287)portcullis.Filter:3:1]: Status change from WaitingForReturnCode to Done
[ERROR] [01/08/2020 11:53:57.861] [cromwell-system-akka.actor.default-dispatcher-61] [akka://cromwell-system/user/cromwell-service/ServiceRegistryActor/KeyValue/KvWriteActor] KvWriteActor Failed to properly process data
cromwell.core.CromwellFatalException: java.sql.BatchUpdateException: Data truncation: Data too long for column 'STORE_VALUE' at row 1
	at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:47)
	at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:38)
	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:417)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:92)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:92)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:49)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.sql.BatchUpdateException: Data truncation: Data too long for column 'STORE_VALUE' at row 1
	at sun.reflect.GeneratedConstructorAccessor65.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at com.mysql.cj.util.Util.handleNewInstance(Util.java:191)
	at com.mysql.cj.util.Util.getInstance(Util.java:166)
	at com.mysql.cj.util.Util.getInstance(Util.java:173)
	at com.mysql.cj.jdbc.exceptions.SQLError.createBatchUpdateException(SQLError.java:224)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchedInserts(ClientPreparedStatement.java:772)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchInternal(ClientPreparedStatement.java:443)
	at com.mysql.cj.jdbc.StatementImpl.executeBatch(StatementImpl.java:814)
	at com.zaxxer.hikari.pool.ProxyStatement.executeBatch(ProxyStatement.java:128)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeBatch(HikariProxyPreparedStatement.java)
	at cromwell.database.slick.SlickDatabase.$anonfun$createBatchUpsert$2(SlickDatabase.scala:259)
	at slick.jdbc.JdbcBackend$SessionDef.withPreparedStatement(JdbcBackend.scala:386)
	at slick.jdbc.JdbcBackend$SessionDef.withPreparedStatement$(JdbcBackend.scala:381)
	at slick.jdbc.JdbcBackend$BaseSession.withPreparedStatement(JdbcBackend.scala:448)
	at cromwell.database.slick.SlickDatabase.$anonfun$createBatchUpsert$1(SlickDatabase.scala:253)
	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70)
	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69)
	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275)
	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.mysql.cj.jdbc.exceptions.MysqlDataTruncation: Data truncation: Data too long for column 'STORE_VALUE' at row 1
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:104)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:970)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1109)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeUpdateInternal(ClientPreparedStatement.java:1057)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeLargeUpdate(ClientPreparedStatement.java:1377)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeBatchedInserts(ClientPreparedStatement.java:733)
	... 16 more

Didn't find out why it was failing but could simple transform the in/out steps from Array[Array[File]] to Array[File] and then finally the filtered/merged File for each type of output
** DONE Create a struct for the indexed bams with sample names and strandness
   CLOSED: [2020-01-16 Thu 19:13] SCHEDULED: <2020-01-16 Thu>
   - CLOSING NOTE [2020-01-16 Thu 19:13] \\
     Structs created and collating sample information through the pipeline tasks
     Now I need to update Mikado to take that information and generate the models file correctly
Pass this struct throughout the workflow to keep track of all the information required by the future steps.
** DONE Implement first mikado with long reads and make sure it can be reused without long reads
   CLOSED: [2020-01-23 Thu 11:18] DEADLINE: <2020-01-24 Fri> SCHEDULED: <2020-01-17 Fri>
   - CLOSING NOTE [2020-01-23 Thu 11:18] \\
     Implemented mikado with optionally only long read inputs, and a mixed mikado. Should there be a paired read only mikado? Or is this simply the mixed mikado but no long reads present?
     
     This has been tested, but some parts like Homology and ORFCalling have not been tested yet. This will need to be done at the TESTING stage
Taking advantage of the new structs created for carrying forward information regarding the samples, implement a reusable mikado workflow with optionally long reads
First two big tasks ORFCalling and Homology have been implemented, now working on the next steps Serialise, Pick, Index and Stats <2020-01-21 Tue>
*** DONE Implement the ORF caller as a dependency to mikado given that it can be shared between short-long/long-only
    CLOSED: [2020-01-21 Tue 20:07] SCHEDULED: <2020-01-20 Mon>
    - CLOSING NOTE [2020-01-21 Tue 20:07] \\
      Done, this needs testing against any protein database at the moment but the skeleton is there.
      Blast/Diamond and the SanitiseSquence tasks were implemented in a separate file as they are shared with the homology step as suspected
Started implementation of ORF Caller, seems to have a cleaning step dependency that needs to be checked for multi-use or if is just a single use
Also, check the blast/diamond step for re-use and simply call the wf within other wfs
*** DONE Implement the HomologyWrapper again, as a dependency of mikado and pass it in
    CLOSED: [2020-01-21 Tue 20:09] SCHEDULED: <2020-01-22 Wed>
    - CLOSING NOTE [2020-01-21 Tue 20:09] \\
      The homology wrapper is mostly implemented, again needs testing and checking the defaults are correct.
      This uses the same Blast/Diamond and SanitiseSequence from the ORF calling which was placed in a separate file with only the relevant tasks.
      Needs to be tested against a protein database to check is properly functioning.
** DONE Use ei's version of repeatmodeler
   CLOSED: [2020-01-28 Tue 13:24] SCHEDULED: <2020-01-28 Tue>
   - CLOSING NOTE [2020-01-28 Tue 13:24] \\
     Had to install a nseg, reconfigure headers of RepeatModeler and check that everything was working ok. Now, that this is working I can continue with the other tasks
** DONE Update parameters for the input samples according to meeting <2020-01-29 Wed>
   CLOSED: [2020-01-29 Wed 16:21]
   - CLOSING NOTE [2020-01-29 Wed 16:21] \\
     Updated in the workflow
** DONE Reorganise transcript module workflow into 2 separate parts; mapping and mikado
   CLOSED: [2020-01-29 Wed 17:49]
   - CLOSING NOTE [2020-01-29 Wed 17:49] \\
     Reorganisation done, still need to work on the input cleanup/sanitise and index step to have a complete subdivision of tasks
** DONE Implement the Exonerate pipeline
   CLOSED: [2020-01-30 Thu 18:09] DEADLINE: <2020-01-28 Tue> SCHEDULED: <2020-01-27 Mon>
   - CLOSING NOTE [2020-01-30 Thu 18:09] \\
     Check https://github.com/ljyanesm/annotation-wdl/commit/1b593f.
     
     main workflow currently ending with SucceededState
   - CLOSING NOTE [2020-01-29 Wed 17:52] \\
     Keeping the same structure as what Luca had in the previous pipeline, this is currently implemented and working
This task make take longer than a cople of days, not because of the "chunking" so much as the configuration and checking of the exonerate server.
*** DONE Test performance for having many workers querying the server. Is it efficient? Check how those efficiency curves look like (servers/worker)/speed.
    CLOSED: [2020-01-29 Wed 17:51]
    - CLOSING NOTE [2020-01-29 Wed 17:51] \\
      Can only use up to the number of CPUs in a single node, won't change for now as there's no simple way of expressing this type of process dependency using Cromwell
*** DONE Find a way of starting and stopping the exonerate server with the worker's results as dependencies.
    CLOSED: [2020-01-29 Wed 17:50]
    - CLOSING NOTE [2020-01-29 Wed 17:50] \\
      Does not seem like this is going to be possible, so I am going to reuse the exonerate_wrapper.py script wrote by Luca and leave it as many jobs reloading the database just once and subdividing the input fastas instead (This is working)
This seems difficult to do in practice, requires catching output from the server before starting the workers which does not seem trivial to do in cromwell.
*** DONE Using the exonerate_wrapper.py in it's current form causes the output to be stored in the python process's memory which makes it unviable for using with cromwell. Find alternative!
    CLOSED: [2020-01-30 Thu 18:07]
    - CLOSING NOTE [2020-01-30 Thu 18:07] \\
      The exonerate wrapper was OK, I was simply not checking the input files were correctly generated for it. Project commint https://github.com/ljyanesm/annotation-wdl/commit/1b593f ends with:
      [INFO] [01/30/2020 18:05:01.906] [cromwell-system-akka.dispatchers.engine-dispatcher-20] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor WorkflowActor-2234841c-32a6-46da-90b4-fa7e427e5272 is in a terminal state: WorkflowSucceededState
** DONE Implement RepeatMasker step
   CLOSED: [2020-01-24 Fri 14:56]
   - CLOSING NOTE [2020-01-24 Fri 14:56] \\
     This step has been implemented. It is missing some steps but the main functionality and definition of inputs outputs is there.
* Meetings
** Transcript module meeting <2020-01-29 Wed>
 Overview of the transcript module pipeline

 #+NAME: fig:figure name
 #+CAPTION: figure name
 #+ATTR_ORG: :width 200/250/300/400/500/600
 #+ATTR_LATEX: :width 2.0in
 #+ATTR_HTML: :width 200/250/300/400/500/600px
 [[file:Dropbox/EI/SW-Group/EI-annotation/pipeline_v0.2.JPG]]

 Changes to previous state of the pipeline:
 - Mikado to take in one "custom" set of parameters for each run_type (short, LQ-long, HQ-long, All) (DONE)
 - Sample's short read assemblies to be grouped by label (DONE)
 - Samples to take extra optional parameters: score, is_ref (DONE)
 - LQ-long and HQ-long can be either collapsed or assembled (DONE)
   - Does this mean *all* LQ are to be grouped together and *all* HQ grouped together too?
     I would have expected them to behave similarly to the short reads.
 - Output of mikado_prepare could be collapsed using 'gffread' and then filtered before subsequent stages (serialize, pick).

** GMC/Mikado/REAT meeting <2020-02-05 Wed>
*** GMC
Preparing publication, not production ready but almost there
Has been tested found issues
Find alternative tools to do analysis and then check final output of consolidation of GMC
E-CASP project paper
*** Mikado
Update genes with stop codons
Strip CDS out
Run pick forcing original models with high score
Add UTRs to the original models based on the *new data*

*** REAT
Using LR for intron chains using correct junctions from Illumina data, mikado can do this or junctools

Benchmark!
Details!

*** Portcullis extra development
    
** Response to reviewers <2020-02-12 Wed>
The responses are already almost in place, a few comments and additions to make
https://docs.google.com/document/d/1e925piyMwV___WgEM-PiMmyn31dEVxlI4l2JSe1iiAM/edit
https://docs.google.com/document/d/10ALZKZa5rgN2CwsB85fBcYwwrXq7s1VLn94ijy9av9A/edit
https://docs.google.com/document/d/1FivqsGVOab3AWn7c6a3TiT6xQfahlNZHHoQz7ayuDkQ/edit

* Diagrams
** High quality long read alignment
#+BEGIN_SRC ditaa :file hq_lr_alignment.png

				      
		    +-------------------------------------------------+
		    |          	      				      |
		    |						      v
	  +---------+------+	+----------------+	    +-----------------+
	  | Aligner        |	| Collapse       |	    |                 |
	  +----------------+	+----------------+	    |                 |
	  |  GMAP          |    |  Gffread       |	    |                 |
	  |  Minimap2      |	|                |	    |      DONE	      |
	  |                +--->|                +--------->|                 |
	  |                |	|                |	    |                 |
	  |                |	|                |	    |                 |
	  +----------------+	+----------------+	    +-----------------+

#+END_SRC
** Low quality long read alignment
#+BEGIN_SRC ditaa :file lq_lr_alignment.png

		  +-------------------------------------------------------+
		  |				                          |
		  |							  v
	+---------+-------+	  +------------------+	       +----------------+
	| Aligner         |       | Assembly         |         |                |
	+-----------------+	  +------------------+ 	       |                |
	|  Minimap2       |	  |  Stringtie2      |	       |                |
	|                 |	  |                  | 	       |      DONE      |      	 
	|                 +------>|                  +-------->|                |
	|                 |	  |                  |	       |                |
	|                 |	  |                  |	       |                |
	+-----------------+	  +------------------+	       +----------------+
#+END_SRC

* Notes
** Scripts in cromwell need to be specified as file paths
Script handling needs to happen before the pipeline starts at preparation steps, where paths are specfied for the scripts, maybe a small test run on the script to check not only the file exists but also that it is working correctly.
** <2020-02-11 Tue 17:44> Pipeline submitted to SLURM running as job in cluster
   - CLOSING NOTE [2020-02-11 Tue 21:53] \\
     Worked fine, now need to add the assembly stage of the LR pipeline
All your base belongs to me
** Cromwell *does not* require a server in order to restart jobs, "cromwell run" *is* enough <2020-02-12 Wed>
This needs a mechanism to start a server or check if one is already running before launching a job and possibly a mechanism to kill the server if it's the last job running. Not sure how I will implement this at the moment.
Only run one server per workflow.
Request a VM and run WDL server + DB server.

This is not true, just tested on the cluster and cromwell seems to remember what it had ran previously correctly <2020-02-12 Wed 18:39>
** Issues:  ETIMEDOUT errors on strace, no output 
Had to kill the job directly sending a SIGTERM so that cromwell would close properly, strace of the failing PID attached below:

1583280950.001974 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403767, {1174178, 483726270}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.011393 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.011917 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403769, {1174178, 493670771}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.021585 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.022140 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403771, {1174178, 503867565}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.031786 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.032166 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403773, {1174178, 514087564}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.042173 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.042714 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403775, {1174178, 523466984}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.051377 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.052079 futex(0x7efdfc03b2e4, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x7efdfc03b2e0, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1
1583280950.053110 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403777, {1174178, 533857822}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.061850 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.062389 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403779, {1174178, 544141885}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.072034 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.072595 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403781, {1174178, 553348637}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.081277 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.081797 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403783, {1174178, 563549463}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.091454 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.091974 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403785, {1174178, 573727604}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.101649 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.102188 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403787, {1174178, 583927454}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.111670 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.111831 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403789, {1174178, 593754701}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.121844 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.122376 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403791, {1174178, 604127699}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.132036 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.132604 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403793, {1174178, 613356743}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.141293 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.141826 futex(0x7efe10123e54, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x7efe10123e50, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1
1583280950.142785 futex(0x7efe10123e54, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x7efe10123e50, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1
1583280950.143597 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403795, {1174178, 623346881}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.151466 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.151983 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403797, {1174178, 633736141}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.161647 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.161802 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403799, {1174178, 643725477}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.171817 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.172374 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403801, {1174178, 654113947}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.182017 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.182572 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403803, {1174178, 663310678}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.191246 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.191763 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403805, {1174178, 673515608}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.201425 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.201952 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403807, {1174178, 683698295}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.211828 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.212394 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403809, {1174178, 694143227}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.222039 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.222579 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403811, {1174178, 703331740}, ffffffff) = -1 ETIMEDOUT (Connection timed out)
1583280950.231256 futex(0x7efe24002028, FUTEX_WAKE_PRIVATE, 1) = 0
1583280950.231785 futex(0x7efe10130f34, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x7efe10130f30, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1
1583280950.232876 futex(0x7efe24002054, FUTEX_WAIT_BITSET_PRIVATE, 2403813, {1174178, 714156320}, ffffffff^Cstrace: Process 2738 detached
 <detached ...>
[00:15:50 yanesl@t128n40:~]$ kill -h
-bash: kill: h: invalid signal specification
[00:16:09 yanesl@t128n40:~]$ kill
kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]
[00:16:13 yanesl@t128n40:~]$ kill -s SIGTERM 2645
[00:17:05 yanesl@t128n40:~]$ Connection to t128n40 closed by remote host.
Connection to t128n40 closed.
[00:17:07 yanesl@v0558:~/workarea/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_integrated]$ ls -larth
total 229M
drwxrwx--- 8 yanesl TGAC_ga007  201 Mar  2 17:51 ..
-rwxrwx--- 1 yanesl TGAC_ga007 190M Mar  2 17:58 cromwell.jar
drwxrwx--- 2 yanesl TGAC_ga007   28 Mar  2 18:31 inputs
-rwxrwx--- 1 yanesl TGAC_ga007  196 Mar  2 18:43 submit.command
-rwxrwx--- 1 yanesl TGAC_ga007 3.3K Mar  3 10:27 reat_align_all.0.2.json
-rwxrwx--- 1 yanesl TGAC_ga007 2.3K Mar  3 10:45 cromwell_noserver_slurm.conf
drwxrwx--- 4 yanesl TGAC_ga007   60 Mar  3 10:48 cromwell-executions
drwxrwxrwx 2 yanesl TGAC_ga007   67 Mar  3 20:55 cromwell-workflow-logs
drwxrwx--- 2 yanesl TGAC_ga007  576 Mar  4 00:01 attempt_logs
-rwxrwx--- 1 yanesl TGAC_ga007   60 Mar  4 00:01 options.json
drwxrwx--- 6 yanesl TGAC_ga007  346 Mar  4 00:01 .
-rwxrwx--- 1 yanesl TGAC_ga007 260K Mar  4 00:17 slurm-25943655.out
[00:17:09 yanesl@v0558:~/workarea/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_integrated]$ cat slurm-25943655.out 

File descriptors:
[00:04:55 yanesl@t128n40:~]$ ls -larth /proc/2645/fd
total 0
dr-xr-xr-x 9 yanesl TGAC_ga007  0 Mar  3 20:54 ..
dr-x------ 2 yanesl TGAC_ga007  0 Mar  4 00:04 .
l-wx------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 9 -> /ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_integrated/cromwell-executions/cromwell-db/cromwell-db.app.log
l-wx------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 8 -> /ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_integrated/cromwell-executions/cromwell-db/cromwell-db.log
lrwx------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 7 -> socket:[15929690]
lrwx------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 6 -> /ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_integrated/cromwell-executions/cromwell-db/cromwell-db.lck
lr-x------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 5 -> /ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_integrated/cromwell.jar
lr-x------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 4 -> /ei/software/testing/jdk/9.0.4/src/jdk-9.0.4/lib/modules
lr-x------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 3 -> /var/lib/sss/mc/passwd
l-wx------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 2 -> /ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_integrated/slurm-25943655.out
l-wx------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 14 -> /ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_integrated/cromwell-workflow-logs/workflow.a32daa14-b614-4963-a6ed-04ed038a58ab.log
lr-x------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 13 -> /dev/urandom
lr-x------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 12 -> /dev/random
lrwx------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 11 -> /ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_integrated/cromwell-executions/cromwell-db/cromwell-db.lobs
lrwx------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 10 -> /ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_integrated/cromwell-executions/cromwell-db/cromwell-db.data
l-wx------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 1 -> /ei/workarea/users/yanesl/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/run_integrated/slurm-25943655.out
lr-x------ 1 yanesl TGAC_ga007 64 Mar  4 00:04 0 -> /dev/null

Not sure where the ETIMEDOUT is coming from yet... Will need to keep this in check.
** TransDecoder observations
Only trains predict on 5000 longest transcripts
** Prodigal
Requires at least IDEAL_SINGLE_GENOME = 100000 bases 

** Results for transcriptome module using Prodigal+Diamond at
Pipeline from 16-04-2020
/ei/workarea/group-ga/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/scaffold6/cromwell-executions/ei_annotation/0ca379dd-17c3-4d3a-abba-fd3b8a36f37a
** Results using TransDecoder+Blast at
Pipeline from 08-04-2020
/ei/workarea/group-ga/Projects/CB-GENANNO-468_REAT-transcriptome_module/Analysis/scaffold6/cromwell-executions/ei_annotation/b747d1dd-5a1d-4ca9-a72a-2125321b6614
* Write up
** Evaluation categories for WF managers:
Subworkflow support
Cloud support
Retry, Retry w/ augmented resources
Scatter/Gather
Conditional tasks
Optional inputs
Expressiveness? (Terseness?)
Documentation
Development (Active, sustainable, inactive)
Usage (How many?, who?, where?)
Execution engines ( What can run it? ) 
Support ( User support )

Measurable metrics:
Time taken to start
Time per X jobs
Memory required per X jobs
