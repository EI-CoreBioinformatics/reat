{
    database {
        profile = "slick.jdbc.HsqldbProfile$"
        db {
            driver = "org.hsqldb.jdbcDriver"
            url = """
            jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;
            shutdown=false;
            hsqldb.default_table_type=cached;hsqldb.tx=mvcc;
            hsqldb.result_max_memory_rows=10000;
            hsqldb.large_data=true;
            hsqldb.applog=1;
            hsqldb.lob_compressed=true;
            hsqldb.script_format=3
            """
            connectionTimeout = 120000
            numThreads = 1
            }
    }

    concurrent-job-limit = 2
    max-concurrent-workflows = 1

    call-caching {
    # Allows re-use of existing results for jobs you've already run
    # (default: false)
    enabled = true

    # Whether to invalidate a cache result forever if we cannot reuse them. Disable this if you expect some cache copies
    # to fail for external reasons which should not invalidate the cache (e.g. auth differences between users):
    # (default: true)
    invalidate-bad-cache-results = true
  }
  backend {
    default = SLURM
    providers {
      SLURM {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
        config {
          runtime-attributes = """
          Int runtime_minutes = 1440
          Int cpus = 4
          Int requested_memory_mb_per_core = 8000
          String queue = "ei-medium"
          """

          submit = """
              sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \
              ${"-c " + cpus} \
              --mem-per-cpu ${requested_memory_mb_per_core} \
              --wrap "/bin/bash 
              export ml python/3.6.0-foss-2016a; 
              WORKON_HOME=$HOME/.virtualenvs; 
              source /ei/software/testing/EasyBuild/3.1.0/software/Python/3.6.0-foss-2016a/bin/virtualenvwrapper.sh; 
              ml samtools; 
              source minimap2-r974; 
              ${script}"
          """
          kill = "scancel ${job_id}"
          check-alive = "squeue -j ${job_id}"
          job-id-regex = "Submitted batch job (\\d+).*"
        }
      }
    }
  }
}
